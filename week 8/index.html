<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Coalball Gallery</title>

    <link rel="stylesheet" href="style.css">

    <script src="libraries/p5.min.js"></script>
    <script src="libraries/p5.sound.min.js"></script>
    <script src="https://unpkg.com/ml5@latest/dist/ml5.min.js"></script>
  </head>

  <body>
    <main>

      <section class="documentation">
        <h1>Unstable Gestures</h1>

        <p class="intro">
          This project is an interactive system that uses machine learning
          (Teachable Machine + ml5.js) to recognize hand gestures through a webcam.
        </p>

        <h2>Big Idea</h2>
        <p>
          The system tries to understand human hand gestures, but it often makes
          mistakes. Small changes in angle, distance, or lighting can confuse the
          model. I treat these mistakes as part of the experience, not as errors.
        </p>

        <h2>How the System Works</h2>
        <p>
          A camera tracks the user’s hand in real time.
          The model classifies the hand into three gestures:
          <strong>scissor</strong>, <strong>scissor 2</strong>, and <strong>yeah</strong>.
          Each gesture triggers a different emoji on the screen.
        </p>

        <h2>What the Technology Can Do</h2>
        <ul>
          <li>Recognize clear and exaggerated hand gestures</li>
          <li>Respond in real time using a webcam</li>
          <li>Learn from a small amount of training data</li>
        </ul>

        <h2>What the Technology Cannot Do</h2>
        <ul>
          <li>Understand very subtle hand differences</li>
          <li>Work well under changing light conditions</li>
          <li>Know the user’s intention</li>
          <li>Stay consistent when the hand moves slightly</li>
        </ul>

        <h2>What I Found Difficult</h2>
        <p>
          The model often looks confident even when it is wrong.
          Similar hand poses are easily confused.
          Natural hand movement is harder for the system than exaggerated gestures.
        </p>

        <h2>Backup Plans</h2>
        <p>
          <strong>Plan A:</strong> Real-time hand gesture recognition with three classes.
        </p>
        <p>
          <strong>Plan B:</strong> Reduce the number of gestures to make recognition more stable.
        </p>
        <p>
          <strong>Plan C:</strong> Use pre-recorded video or keyboard input to simulate the system
          if live recognition fails.
        </p>

        <h2>Conclusion</h2>
        <p>
          This project shows how machines simplify complex human gestures.
          The mistakes and misunderstandings reveal the limits of machine vision.
        </p>
      </section>

    </main>

    <script src="sketch.js"></script>
  </body>
</html>
